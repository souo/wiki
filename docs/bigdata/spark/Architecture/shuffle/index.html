<!doctype html>
<html lang="en" dir="ltr" class="docs-wrapper docs-doc-page docs-version-current plugin-docs plugin-id-default docs-doc-id-bigdata/spark/Architecture/shuffle">
<head>
<meta charset="UTF-8">
<meta name="viewport" content="width=device-width,initial-scale=1">
<meta name="generator" content="Docusaurus v2.0.1">
<link rel="alternate" type="application/rss+xml" href="/wiki/blog/rss.xml" title="Dev Wiki RSS Feed">
<link rel="alternate" type="application/atom+xml" href="/wiki/blog/atom.xml" title="Dev Wiki Atom Feed">




<link rel="stylesheet" href="/wiki/katex/katex.min.css"><title data-rh="true">shuffle机制 | Dev Wiki</title><meta data-rh="true" name="twitter:card" content="summary_large_image"><meta data-rh="true" property="og:url" content="http://souo.github.io/wiki/docs/bigdata/spark/Architecture/shuffle"><meta data-rh="true" name="docusaurus_locale" content="en"><meta data-rh="true" name="docsearch:language" content="en"><meta data-rh="true" name="docusaurus_version" content="current"><meta data-rh="true" name="docusaurus_tag" content="docs-default-current"><meta data-rh="true" name="docsearch:version" content="current"><meta data-rh="true" name="docsearch:docusaurus_tag" content="docs-default-current"><meta data-rh="true" property="og:title" content="shuffle机制 | Dev Wiki"><meta data-rh="true" name="description" content="shuffle 机制用于上游和下游 stage 之间传递数据。 shuffle 解决的问题是如何将数据重新组织， 使其能够在上游和下游的task之间传递和计算。"><meta data-rh="true" property="og:description" content="shuffle 机制用于上游和下游 stage 之间传递数据。 shuffle 解决的问题是如何将数据重新组织， 使其能够在上游和下游的task之间传递和计算。"><link data-rh="true" rel="canonical" href="http://souo.github.io/wiki/docs/bigdata/spark/Architecture/shuffle"><link data-rh="true" rel="alternate" href="http://souo.github.io/wiki/docs/bigdata/spark/Architecture/shuffle" hreflang="en"><link data-rh="true" rel="alternate" href="http://souo.github.io/wiki/docs/bigdata/spark/Architecture/shuffle" hreflang="x-default"><link data-rh="true" rel="preconnect" href="https://undefined-dsn.algolia.net" crossorigin="anonymous"><link rel="stylesheet" href="/wiki/assets/css/styles.a6de386b.css">
<link rel="preload" href="/wiki/assets/js/runtime~main.4af80907.js" as="script">
<link rel="preload" href="/wiki/assets/js/main.6f5d8ae1.js" as="script">
</head>
<body class="navigation-with-keyboard">
<script>!function(){function t(t){document.documentElement.setAttribute("data-theme",t)}var e=function(){var t=null;try{t=localStorage.getItem("theme")}catch(t){}return t}();t(null!==e?e:"light")}()</script><div id="__docusaurus">
<div role="region"><a href="#" class="skipToContent_fXgn">Skip to main content</a></div><nav class="navbar navbar--fixed-top"><div class="navbar__inner"><div class="navbar__items"><button aria-label="Navigation bar toggle" class="navbar__toggle clean-btn" type="button" tabindex="0"><svg width="30" height="30" viewBox="0 0 30 30" aria-hidden="true"><path stroke="currentColor" stroke-linecap="round" stroke-miterlimit="10" stroke-width="2" d="M4 7h22M4 15h22M4 23h22"></path></svg></button><a class="navbar__brand" href="/wiki/"><b class="navbar__title text--truncate">知识库</b></a></div><div class="navbar__items navbar__items--right"><a class="navbar__item navbar__link" href="/wiki/get-started">Get Started</a><a class="navbar__item navbar__link" href="/wiki/docs/welcome">Docs</a><a class="navbar__item navbar__link" href="/wiki/blog">Blog</a><div class="navbar__item dropdown dropdown--hoverable dropdown--right"><a href="#" aria-haspopup="true" aria-expanded="false" role="button" class="navbar__link">WIKI</a><ul class="dropdown__menu"><li><a class="dropdown__link" href="/wiki/docs/java/jvm/jvm-architecture">Java</a></li><li><a class="dropdown__link" href="/wiki/docs/bigdata/hbase/hbase-architecture">BigData</a></li><li><a class="dropdown__link" href="/wiki/docs/math/quick-power">math</a></li><li><a class="dropdown__link" href="/wiki/docs/db/profiling/sql">数据库</a></li><li><a class="dropdown__link" href="/wiki/docs/questions/java/class_file">面试题</a></li></ul></div><div class="searchBox_ZlJk"><button type="button" class="DocSearch DocSearch-Button" aria-label="Search"><span class="DocSearch-Button-Container"><svg width="20" height="20" class="DocSearch-Search-Icon" viewBox="0 0 20 20"><path d="M14.386 14.386l4.0877 4.0877-4.0877-4.0877c-2.9418 2.9419-7.7115 2.9419-10.6533 0-2.9419-2.9418-2.9419-7.7115 0-10.6533 2.9418-2.9419 7.7115-2.9419 10.6533 0 2.9419 2.9418 2.9419 7.7115 0 10.6533z" stroke="currentColor" fill="none" fill-rule="evenodd" stroke-linecap="round" stroke-linejoin="round"></path></svg><span class="DocSearch-Button-Placeholder">Search</span></span><span class="DocSearch-Button-Keys"></span></button></div></div></div><div role="presentation" class="navbar-sidebar__backdrop"></div></nav><div class="main-wrapper mainWrapper_z2l0 docsWrapper_BCFX"><button aria-label="Scroll back to top" class="clean-btn theme-back-to-top-button backToTopButton_sjWU" type="button"></button><div class="docPage__5DB"><aside class="theme-doc-sidebar-container docSidebarContainer_b6E3"><div class="sidebar_njMd"><nav class="menu thin-scrollbar menu_SIkG"><ul class="theme-doc-sidebar-menu menu__list"><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist menu__link--sublist-caret" aria-expanded="false" href="/wiki/docs/welcome">Getting Started</a></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist menu__link--sublist-caret" aria-expanded="false" href="/wiki/docs/java/jvm/jvm-architecture">JAVA</a></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist menu__link--sublist-caret" aria-expanded="false" href="/wiki/docs/db/profiling/sql">DB</a></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist menu__link--sublist-caret menu__link--active" aria-expanded="true" href="/wiki/docs/bigdata/hbase/hbase-architecture">BIGDATA</a></div><ul style="display:block;overflow:visible;height:auto" class="menu__list"><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-2 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist menu__link--sublist-caret" aria-expanded="false" tabindex="0" href="/wiki/docs/bigdata/hbase/hbase-architecture">Hbase</a></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-2 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist menu__link--sublist-caret" aria-expanded="false" tabindex="0" href="/wiki/docs/bigdata/hadoop/hadoop-tuning">Hadoop</a></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-2 menu__list-item"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist menu__link--sublist-caret menu__link--active" aria-expanded="true" tabindex="0" href="/wiki/docs/bigdata/spark/turning_spark">Spark</a></div><ul style="display:block;overflow:visible;height:auto" class="menu__list"><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item"><a class="menu__link" tabindex="0" href="/wiki/docs/bigdata/spark/turning_spark">Spark 调优</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item"><a class="menu__link" tabindex="0" href="/wiki/docs/bigdata/spark/strategies-of-spark-join">Spark Join Strategies</a></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-3 menu__list-item"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist menu__link--sublist-caret menu__link--active" aria-expanded="true" tabindex="0" href="/wiki/docs/bigdata/spark/Architecture/Overview">Spark架构及原理</a></div><ul style="display:block;overflow:visible;height:auto" class="menu__list"><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-4 menu__list-item"><a class="menu__link" tabindex="0" href="/wiki/docs/bigdata/spark/Architecture/Overview">概述</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-4 menu__list-item"><a class="menu__link menu__link--active" aria-current="page" tabindex="0" href="/wiki/docs/bigdata/spark/Architecture/shuffle">shuffle机制</a></li></ul></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item"><a class="menu__link" tabindex="0" href="/wiki/docs/bigdata/spark/paper/rdd">Spark RDD（Resilient Distributed Datasets）论文</a></li></ul></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-2 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist menu__link--sublist-caret" aria-expanded="false" tabindex="0" href="/wiki/docs/bigdata/raft">一致性算法</a></div></li></ul></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist menu__link--sublist-caret" aria-expanded="false" href="/wiki/docs/math/quick-power">MATH</a></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist menu__link--sublist-caret" aria-expanded="false" href="/wiki/docs/momd/momd-1">MOMD</a></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist menu__link--sublist-caret" aria-expanded="false" href="/wiki/docs/NLP/supervised-ml-sentiment-analysis">NLP</a></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist menu__link--sublist-caret" aria-expanded="false" href="/wiki/docs/git/git-pathspece">GIT</a></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist menu__link--sublist-caret" aria-expanded="false" href="/wiki/docs/programming/regex">PROGRAMMING</a></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist menu__link--sublist-caret" aria-expanded="false" href="/wiki/docs/questions/java/class_file">INTERVIEWS</a></div></li></ul></nav></div></aside><main class="docMainContainer_gTbr"><div class="container padding-top--md padding-bottom--lg"><div class="row"><div class="col docItemCol_VOVn"><div class="docItemContainer_Djhp"><article><nav class="theme-doc-breadcrumbs breadcrumbsContainer_Z_bl" aria-label="Breadcrumbs"><ul class="breadcrumbs" itemscope="" itemtype="https://schema.org/BreadcrumbList"><li class="breadcrumbs__item"><a aria-label="Home page" class="breadcrumbs__link" href="/wiki/"><svg viewBox="0 0 24 24" class="breadcrumbHomeIcon_OVgt"><path d="M10 19v-5h4v5c0 .55.45 1 1 1h3c.55 0 1-.45 1-1v-7h1.7c.46 0 .68-.57.33-.87L12.67 3.6c-.38-.34-.96-.34-1.34 0l-8.36 7.53c-.34.3-.13.87.33.87H5v7c0 .55.45 1 1 1h3c.55 0 1-.45 1-1z" fill="currentColor"></path></svg></a></li><li class="breadcrumbs__item"><span class="breadcrumbs__link">BIGDATA</span><meta itemprop="position" content="1"></li><li class="breadcrumbs__item"><span class="breadcrumbs__link">Spark</span><meta itemprop="position" content="2"></li><li class="breadcrumbs__item"><span class="breadcrumbs__link">Spark架构及原理</span><meta itemprop="position" content="3"></li><li itemscope="" itemprop="itemListElement" itemtype="https://schema.org/ListItem" class="breadcrumbs__item breadcrumbs__item--active"><span class="breadcrumbs__link" itemprop="name">shuffle机制</span><meta itemprop="position" content="4"></li></ul></nav><div class="tocCollapsible_ETCw theme-doc-toc-mobile tocMobile_ITEo"><button type="button" class="clean-btn tocCollapsibleButton_TO0P">On this page</button></div><div class="theme-doc-markdown markdown"><header><h1>shuffle机制</h1></header><p>shuffle 机制用于上游和下游 stage 之间传递数据。 shuffle 解决的问题是如何将数据重新组织， 使其能够在上游和下游的task之间传递和计算。</p><p>如果只是简单的数据传递，则只需将数据分区，通过网络传输即可，没有太大的难度。 但 shuffle 机制还需要进行各种类型的计算（如聚合、排序等），而且数据量一般都很大。如何支持不同类型的计算，如何提高 shuffle的性能，都是shuffle设计的难点。</p><h2 class="anchor anchorWithStickyNavbar_LWe7" id="shuffle设计的难点">shuffle设计的难点<a class="hash-link" href="#shuffle设计的难点" title="Direct link to heading">​</a></h2><ul><li>计算的多样性: shuffle 分为shuffle write 和 shuffle read 两个阶段。<ul><li>前者主要解决上游stage输出数据的分区问题，</li><li>后者主要用于解决下游stage 从上游 stage 获取数据、重新组织数据、并为后续操作提供数据的问题。</li><li>在进行 shuffle write 和 shuffle read 时有些操作需要对数据进行一定的计算。<ul><li><code>groupByKey()</code>  需要将 shuffle Read 的 <code>&lt;K, V&gt;</code> 聚合成 <code>&lt;K, List&lt;V&gt;</code></li><li><code>reduceByKey()</code> 需要在 shuffle writer 做 <code>combine()</code></li><li><code>sortByKey()</code> 需要做排序</li></ul></li></ul></li><li>计算的耦合性：有些操作包含了用户的自定义聚合函数, 如 <code>aggregateByKey</code>, <code>reduceByKey</code> 等</li><li>中间数据的存储</li></ul><h2 class="anchor anchorWithStickyNavbar_LWe7" id="spark-shuffle-要解决的问题">Spark Shuffle 要解决的问题<a class="hash-link" href="#spark-shuffle-要解决的问题" title="Direct link to heading">​</a></h2><p>我们先从总体的角度来看一下Spark Shuffle要解决哪些问题，以及大致的解决方案是什么。</p><ul><li>如何灵活支持不同计算的场景下不同的需求？排序、聚合、分区？<ul><li>通过灵活的框架设计来满足不同的需求</li></ul></li><li>如何应对大数据量的情况下面临的内存压力？<ul><li>通过内存 + 磁盘 + 数据结构设计来解决内存问题</li></ul></li><li>如何保证Shuffle过程的高性能问题？<ul><li>减少网络传输</li><li>map端的reduce</li><li>减少碎小文件</li><li>按partitionId进行排序并合并多个碎文件为一个，然后加上分区文件索引供下游使用</li></ul></li></ul><h2 class="anchor anchorWithStickyNavbar_LWe7" id="spark-shuffle-框架的设计">spark shuffle 框架的设计<a class="hash-link" href="#spark-shuffle-框架的设计" title="Direct link to heading">​</a></h2><h3 class="anchor anchorWithStickyNavbar_LWe7" id="shuffle-write-的设计与实现">shuffle Write 的设计与实现<a class="hash-link" href="#shuffle-write-的设计与实现" title="Direct link to heading">​</a></h3><p>在Shuffle Write阶段，数据操作需要提供的是分区、聚合和排序三个数据功能。但可能在数据场景里，需要的功能只是其中一个或者两个，因此Spark Shuffle的Write整体框架设计成灵活的 <code>map --&gt; combine（可选）--&gt; sort(可选) --&gt; partitions</code> 。具体的框架如下图所示:</p><p><img loading="lazy" src="/wiki/assets/images/Spark_Shuffle_Write-4d64dcfb170501d650b4af70b0945265.png" width="1061" height="361" class="img_ev3q"></p><h4 class="anchor anchorWithStickyNavbar_LWe7" id="1-仅需要map不需要combine和sort的场景">1. 仅需要map，不需要combine和sort的场景<a class="hash-link" href="#1-仅需要map不需要combine和sort的场景" title="Direct link to heading">​</a></h4><p>这种情况最简单，只需要考虑分区操作， spark中对应的实现为 <a href="https://github1s.com/apache/spark/blob/HEAD/core/src/main/java/org/apache/spark/shuffle/sort/BypassMergeSortShuffleWriter.java" target="_blank" rel="noopener noreferrer">BypassMergeSortShuffleWriter</a> 如下图所示：
<img loading="lazy" src="/wiki/assets/images/OnlyMap_ShuffleWrite-6c63da33e26025611dd9338d67611585.png" width="1011" height="311" class="img_ev3q"></p><p>每个partition对应一个文件，map任务完成后将单个结果记录直接写出到对应的分区, 然后将这些分区文件合并起来形成一个输出文件。</p><ul><li>优点</li></ul><p>速度快，不需要排序</p><ul><li>缺点
很显然当分区数非常多的时候，BypassMergeSortShuffleWriter是不大适合的，因为要写出与分区数相同数量的文件，意味这同时要打开分区数个文件（创建分区数这么多的文件流），并同时需要分区数这么多的序列化器。</li></ul><p>正是因为存在上述这个缺点，所以使用时需要指定一个门限bypassMergeThreshold。这个门限指定以后，程序执行时在选择ShuffleWriter会进行判断，如果分区数大于这个门限，就不用BypassMergeSortShuffleWriter来写出磁盘。</p><div class="codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#F8F8F2;--prism-background-color:#282A36"><div class="codeBlockContent_biex"><pre tabindex="0" class="prism-code language-text codeBlock_bY9V thin-scrollbar"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#F8F8F2"><span class="token plain">spark.shuffle.sort.bypassMergeThreshold= // 默认值是200</span><br></span></code></pre><div class="buttonGroup__atx"><button type="button" aria-label="Copy code to clipboard" title="Copy" class="clean-btn"><span class="copyButtonIcons_eSgA" aria-hidden="true"><svg class="copyButtonIcon_y97N" viewBox="0 0 24 24"><path d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg class="copyButtonSuccessIcon_LjdS" viewBox="0 0 24 24"><path d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div><ul><li>使用场景
通过优缺点分析，可以看到，这种处理方式只适合分区个数比较小的情况下(可以通过<code>spark.shuffle.sort.byPassMergeThreshold</code> 设置)，速度比较快。另外也不需要额外的combine和sort的场景，比如简单的partitionBy(), groupBy()类似的transformation操作。</li></ul><h3 class="anchor anchorWithStickyNavbar_LWe7" id="需要map需要combine的场景">需要map，需要combine的场景<a class="hash-link" href="#需要map需要combine的场景" title="Direct link to heading">​</a></h3><p><img loading="lazy" src="/wiki/assets/images/MapandCombine_ShuffleWrite-65091796cc5d45c744a174782933d846.png" width="1183" height="351" class="img_ev3q"></p><ol><li><p>Map和在线聚合
对于输入的record，经过map运算后，会放进一个类似HashMap的数据结构里（PartitionedAppendOnlyMap），如果HashMap里key存在，那么会将该record的值和对应结构里的value进行combine操作，然后更新key在这个HashMap里的数值，实现在线聚合的功能。否则，直接将record的值更新到HashMap里即可。
其中这里的key = partitionId + record key。</p></li><li><p>Sort&amp;Spill
当HashMap里不够存放时，会先进行扩容，扩容为原来的两倍。如果还存放不下，然后会将HashMap里的record排序后放入磁盘里。然后清空进行HashMap，继续进行后续的在线聚合操作。
其中这里对record进行排序的key:</p><div class="codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#F8F8F2;--prism-background-color:#282A36"><div class="codeBlockContent_biex"><pre tabindex="0" class="prism-code language-text codeBlock_bY9V thin-scrollbar"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#F8F8F2"><span class="token plain">-  如果需要map端按照record key排序，那么这里排序的 `key = partitionId + record key`</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">- 否则，这里的排序 `key = partitionId`</span><br></span></code></pre><div class="buttonGroup__atx"><button type="button" aria-label="Copy code to clipboard" title="Copy" class="clean-btn"><span class="copyButtonIcons_eSgA" aria-hidden="true"><svg class="copyButtonIcon_y97N" viewBox="0 0 24 24"><path d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg class="copyButtonSuccessIcon_LjdS" viewBox="0 0 24 24"><path d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div></li><li><p>Sort&amp;Merge
在输出文件时，会将Spill到磁盘的和内存里的数据，进行Sort和Merge操作，然后按PartitionId输出数据。最终会生成一个输出文件(存放该map task产生的所有的分区文件) + 分区数据索引文件供下游Shuffle Read使用。</p></li></ol><p>实现</p><ul><li>SortShuffleWriter</li></ul><h3 class="anchor anchorWithStickyNavbar_LWe7" id="shuffle-read-的设计与实现">shuffle read 的设计与实现<a class="hash-link" href="#shuffle-read-的设计与实现" title="Direct link to heading">​</a></h3><p>在Shuffle Write阶段，数据操作需要提供跨节点读取、聚合和排序。同shuffle write 一样 不是所有的数据操作都需要这些功能。因此Spark Shuffle的Read整体框架设计成&quot;数据获取-&gt;聚合-&gt;排序&quot;。</p><p><img loading="lazy" src="/wiki/assets/images/spark_shuffle_read-d497da8f5ca68df5df5d2e445a6a3d32.png" width="1864" height="856" class="img_ev3q">
reduce task不断从各个map task的分区文件中获取数据（fetch），然后使用类型hashMap的数据结果对数据进行在线聚合。聚合完成后将数据放入类似array的数组中进行排序。如果不需要聚合和排序，可以去掉对应的功能。</p></div></article><nav class="pagination-nav docusaurus-mt-lg" aria-label="Docs pages navigation"><a class="pagination-nav__link pagination-nav__link--prev" href="/wiki/docs/bigdata/spark/Architecture/Overview"><div class="pagination-nav__sublabel">Previous</div><div class="pagination-nav__label">概述</div></a><a class="pagination-nav__link pagination-nav__link--next" href="/wiki/docs/bigdata/spark/paper/rdd"><div class="pagination-nav__sublabel">Next</div><div class="pagination-nav__label">Spark RDD（Resilient Distributed Datasets）论文</div></a></nav></div></div><div class="col col--3"><div class="tableOfContents_bqdL thin-scrollbar theme-doc-toc-desktop"><ul class="table-of-contents table-of-contents__left-border"><li><a href="#shuffle设计的难点" class="table-of-contents__link toc-highlight">shuffle设计的难点</a></li><li><a href="#spark-shuffle-要解决的问题" class="table-of-contents__link toc-highlight">Spark Shuffle 要解决的问题</a></li><li><a href="#spark-shuffle-框架的设计" class="table-of-contents__link toc-highlight">spark shuffle 框架的设计</a><ul><li><a href="#shuffle-write-的设计与实现" class="table-of-contents__link toc-highlight">shuffle Write 的设计与实现</a></li><li><a href="#需要map需要combine的场景" class="table-of-contents__link toc-highlight">需要map，需要combine的场景</a></li><li><a href="#shuffle-read-的设计与实现" class="table-of-contents__link toc-highlight">shuffle read 的设计与实现</a></li></ul></li></ul></div></div></div></div></main></div></div></div>
<script src="/wiki/assets/js/runtime~main.4af80907.js"></script>
<script src="/wiki/assets/js/main.6f5d8ae1.js"></script>
</body>
</html>