<!doctype html>
<html lang="en" dir="ltr" class="docs-wrapper docs-doc-page docs-version-current plugin-docs plugin-id-default docs-doc-id-bigdata/spark/turning_spark">
<head>
<meta charset="UTF-8">
<meta name="viewport" content="width=device-width,initial-scale=1">
<meta name="generator" content="Docusaurus v2.0.1">
<link rel="alternate" type="application/rss+xml" href="/wiki/blog/rss.xml" title="Dev Wiki RSS Feed">
<link rel="alternate" type="application/atom+xml" href="/wiki/blog/atom.xml" title="Dev Wiki Atom Feed">




<link rel="stylesheet" href="/wiki/katex/katex.min.css"><title data-rh="true">Spark 调优 | Dev Wiki</title><meta data-rh="true" name="twitter:card" content="summary_large_image"><meta data-rh="true" property="og:url" content="http://souo.github.io/wiki/docs/bigdata/spark/turning_spark"><meta data-rh="true" name="docusaurus_locale" content="en"><meta data-rh="true" name="docsearch:language" content="en"><meta data-rh="true" name="docusaurus_version" content="current"><meta data-rh="true" name="docusaurus_tag" content="docs-default-current"><meta data-rh="true" name="docsearch:version" content="current"><meta data-rh="true" name="docsearch:docusaurus_tag" content="docs-default-current"><meta data-rh="true" property="og:title" content="Spark 调优 | Dev Wiki"><meta data-rh="true" name="description" content="由于大多数Spark计算都在内存中，所以集群中的任何资源(CPU、网络带宽或内存)都可能成为Spark程序的瓶颈。"><meta data-rh="true" property="og:description" content="由于大多数Spark计算都在内存中，所以集群中的任何资源(CPU、网络带宽或内存)都可能成为Spark程序的瓶颈。"><link data-rh="true" rel="canonical" href="http://souo.github.io/wiki/docs/bigdata/spark/turning_spark"><link data-rh="true" rel="alternate" href="http://souo.github.io/wiki/docs/bigdata/spark/turning_spark" hreflang="en"><link data-rh="true" rel="alternate" href="http://souo.github.io/wiki/docs/bigdata/spark/turning_spark" hreflang="x-default"><link data-rh="true" rel="preconnect" href="https://undefined-dsn.algolia.net" crossorigin="anonymous"><link rel="stylesheet" href="/wiki/assets/css/styles.a6de386b.css">
<link rel="preload" href="/wiki/assets/js/runtime~main.356aa08e.js" as="script">
<link rel="preload" href="/wiki/assets/js/main.5a4fb01b.js" as="script">
</head>
<body class="navigation-with-keyboard">
<script>!function(){function t(t){document.documentElement.setAttribute("data-theme",t)}var e=function(){var t=null;try{t=localStorage.getItem("theme")}catch(t){}return t}();t(null!==e?e:"light")}()</script><div id="__docusaurus">
<div role="region"><a href="#" class="skipToContent_fXgn">Skip to main content</a></div><nav class="navbar navbar--fixed-top"><div class="navbar__inner"><div class="navbar__items"><button aria-label="Navigation bar toggle" class="navbar__toggle clean-btn" type="button" tabindex="0"><svg width="30" height="30" viewBox="0 0 30 30" aria-hidden="true"><path stroke="currentColor" stroke-linecap="round" stroke-miterlimit="10" stroke-width="2" d="M4 7h22M4 15h22M4 23h22"></path></svg></button><a class="navbar__brand" href="/wiki/"><b class="navbar__title text--truncate">知识库</b></a></div><div class="navbar__items navbar__items--right"><a class="navbar__item navbar__link" href="/wiki/get-started">Get Started</a><a class="navbar__item navbar__link" href="/wiki/docs/welcome">Docs</a><a class="navbar__item navbar__link" href="/wiki/blog">Blog</a><div class="navbar__item dropdown dropdown--hoverable dropdown--right"><a href="#" aria-haspopup="true" aria-expanded="false" role="button" class="navbar__link">WIKI</a><ul class="dropdown__menu"><li><a class="dropdown__link" href="/wiki/docs/java/jvm/jvm-architecture">Java</a></li><li><a class="dropdown__link" href="/wiki/docs/bigdata/hbase/hbase-architecture">BigData</a></li><li><a class="dropdown__link" href="/wiki/docs/math/quick-power">math</a></li><li><a class="dropdown__link" href="/wiki/docs/db/profiling/sql">数据库</a></li><li><a class="dropdown__link" href="/wiki/docs/questions/java/class_file">面试题</a></li></ul></div><div class="searchBox_ZlJk"><button type="button" class="DocSearch DocSearch-Button" aria-label="Search"><span class="DocSearch-Button-Container"><svg width="20" height="20" class="DocSearch-Search-Icon" viewBox="0 0 20 20"><path d="M14.386 14.386l4.0877 4.0877-4.0877-4.0877c-2.9418 2.9419-7.7115 2.9419-10.6533 0-2.9419-2.9418-2.9419-7.7115 0-10.6533 2.9418-2.9419 7.7115-2.9419 10.6533 0 2.9419 2.9418 2.9419 7.7115 0 10.6533z" stroke="currentColor" fill="none" fill-rule="evenodd" stroke-linecap="round" stroke-linejoin="round"></path></svg><span class="DocSearch-Button-Placeholder">Search</span></span><span class="DocSearch-Button-Keys"></span></button></div></div></div><div role="presentation" class="navbar-sidebar__backdrop"></div></nav><div class="main-wrapper mainWrapper_z2l0 docsWrapper_BCFX"><button aria-label="Scroll back to top" class="clean-btn theme-back-to-top-button backToTopButton_sjWU" type="button"></button><div class="docPage__5DB"><aside class="theme-doc-sidebar-container docSidebarContainer_b6E3"><div class="sidebar_njMd"><nav class="menu thin-scrollbar menu_SIkG"><ul class="theme-doc-sidebar-menu menu__list"><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist menu__link--sublist-caret" aria-expanded="false" href="/wiki/docs/welcome">Getting Started</a></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist menu__link--sublist-caret" aria-expanded="false" href="/wiki/docs/java/jvm/jvm-architecture">JAVA</a></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist menu__link--sublist-caret" aria-expanded="false" href="/wiki/docs/db/profiling/sql">DB</a></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist menu__link--sublist-caret menu__link--active" aria-expanded="true" href="/wiki/docs/bigdata/hbase/hbase-architecture">BIGDATA</a></div><ul style="display:block;overflow:visible;height:auto" class="menu__list"><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-2 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist menu__link--sublist-caret" aria-expanded="false" tabindex="0" href="/wiki/docs/bigdata/hbase/hbase-architecture">Hbase</a></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-2 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist menu__link--sublist-caret" aria-expanded="false" tabindex="0" href="/wiki/docs/bigdata/hadoop/hadoop-tuning">Hadoop</a></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-2 menu__list-item"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist menu__link--sublist-caret menu__link--active" aria-expanded="true" tabindex="0" href="/wiki/docs/bigdata/spark/turning_spark">Spark</a></div><ul style="display:block;overflow:visible;height:auto" class="menu__list"><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item"><a class="menu__link menu__link--active" aria-current="page" tabindex="0" href="/wiki/docs/bigdata/spark/turning_spark">Spark 调优</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item"><a class="menu__link" tabindex="0" href="/wiki/docs/bigdata/spark/strategies-of-spark-join">Spark Join Strategies</a></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-3 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist menu__link--sublist-caret" aria-expanded="false" tabindex="0" href="/wiki/docs/bigdata/spark/Architecture/Overview">Spark架构及原理</a></div></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item"><a class="menu__link" tabindex="0" href="/wiki/docs/bigdata/spark/paper/rdd">Spark RDD（Resilient Distributed Datasets）论文</a></li></ul></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-2 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist menu__link--sublist-caret" aria-expanded="false" tabindex="0" href="/wiki/docs/bigdata/raft">一致性算法</a></div></li></ul></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist menu__link--sublist-caret" aria-expanded="false" href="/wiki/docs/math/quick-power">MATH</a></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist menu__link--sublist-caret" aria-expanded="false" href="/wiki/docs/momd/momd-1">MOMD</a></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist menu__link--sublist-caret" aria-expanded="false" href="/wiki/docs/NLP/supervised-ml-sentiment-analysis">NLP</a></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist menu__link--sublist-caret" aria-expanded="false" href="/wiki/docs/git/git-pathspece">GIT</a></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist menu__link--sublist-caret" aria-expanded="false" href="/wiki/docs/questions/java/class_file">INTERVIEWS</a></div></li></ul></nav></div></aside><main class="docMainContainer_gTbr"><div class="container padding-top--md padding-bottom--lg"><div class="row"><div class="col docItemCol_VOVn"><div class="docItemContainer_Djhp"><article><nav class="theme-doc-breadcrumbs breadcrumbsContainer_Z_bl" aria-label="Breadcrumbs"><ul class="breadcrumbs" itemscope="" itemtype="https://schema.org/BreadcrumbList"><li class="breadcrumbs__item"><a aria-label="Home page" class="breadcrumbs__link" href="/wiki/"><svg viewBox="0 0 24 24" class="breadcrumbHomeIcon_OVgt"><path d="M10 19v-5h4v5c0 .55.45 1 1 1h3c.55 0 1-.45 1-1v-7h1.7c.46 0 .68-.57.33-.87L12.67 3.6c-.38-.34-.96-.34-1.34 0l-8.36 7.53c-.34.3-.13.87.33.87H5v7c0 .55.45 1 1 1h3c.55 0 1-.45 1-1z" fill="currentColor"></path></svg></a></li><li class="breadcrumbs__item"><span class="breadcrumbs__link">BIGDATA</span><meta itemprop="position" content="1"></li><li class="breadcrumbs__item"><span class="breadcrumbs__link">Spark</span><meta itemprop="position" content="2"></li><li itemscope="" itemprop="itemListElement" itemtype="https://schema.org/ListItem" class="breadcrumbs__item breadcrumbs__item--active"><span class="breadcrumbs__link" itemprop="name">Spark 调优</span><meta itemprop="position" content="3"></li></ul></nav><div class="tocCollapsible_ETCw theme-doc-toc-mobile tocMobile_ITEo"><button type="button" class="clean-btn tocCollapsibleButton_TO0P">On this page</button></div><div class="theme-doc-markdown markdown"><header><h1>Spark 调优</h1></header><p>由于大多数Spark计算都在内存中，所以集群中的任何资源(CPU、网络带宽或内存)都可能成为Spark程序的瓶颈。</p><p>大多数情况下，如果数据适合存储在内存中，那么瓶颈就是网络带宽，但是有时，你还需要进行一些调优，例如<a href="http://spark.apache.org/docs/latest/rdd-programming-guide.html" target="_blank" rel="noopener noreferrer">以序列化的形式存储RDD</a>，以减少内存使用。</p><p>本指南将涵盖两个主要主题: 数据序列化和内存调优。数据序列化对于良好的网络性能至关重要，它还可以减少内存使用。我们还概述了几个较小的主题。</p><h2 class="anchor anchorWithStickyNavbar_LWe7" id="数据序列化">数据序列化<a class="hash-link" href="#数据序列化" title="Direct link to heading">​</a></h2><p>序列化在任何分布式应用程序的性能中都扮演着重要的角色。将对象序列化成或消耗大量字节的速度较慢的格式将极大地降低计算速度。通常，这是优化Spark应用程序的第一件事。Spark的目标是在便利性(允许你在操作中使用任何Java类型)和性能之间取得平衡。它提供了两个序列化库:</p><ul><li><p><a href="https://docs.oracle.com/javase/8/docs/api/java/io/Serializable.html" target="_blank" rel="noopener noreferrer">Java序列化</a>:  默认情况下,使用Java的 Spark 序列化对象 <code>ObjectOutputStream</code> 框架,你可以使用任何实现了 <a href="https://docs.oracle.com/javase/8/docs/api/java/io/Serializable.html" target="_blank" rel="noopener noreferrer">java.io.Serializable</a> 的类与它一起使用。你还可以通过继承  <a href="https://docs.oracle.com/javase/8/docs/api/java/io/Externalizable.html" target="_blank" rel="noopener noreferrer">java.io.Externalizable</a>  来更深入地控制序列化的性能。Java序列化有着灵活，但通常非常缓慢的特性，会导致许多类的大型序列化格式。</p></li><li><p><a href="https://github.com/EsotericSoftware/kryo" target="_blank" rel="noopener noreferrer">Kryo serialization</a>:  Spark还可以使用Kryo库(<code>version 4</code>)更快地序列化对象。Kryo比Java序列化要快得多(通常多达10倍)，也更紧凑，但它不支持所有的 <code>Serializable</code> 类型，并且要求你预先 <em>注册</em> 将在程序中使用的类，以获得最佳性能。</p></li></ul><p>你可以通过使用 SparkConf 初始化作业并调用 <code>conf.set(&quot;spark.serializer&quot;, org.apache.spark.serializer.KryoSerializer&quot;)</code>，切换使用 <code>Kryo</code> 来进行序列化。此设置配置的序列化程序不仅用于在工作节点之间数据 <code>shuffle</code>，而且还用于将 <code>RDD</code> 序列化到磁盘。Kryo不是默认的 <code>serializer</code> 的唯一原因是自定义的注册要求，但是我们建议在任何网络密集型应用程序中尝试它。自从 Spark 2.0.0 以来，我们在使用简单类型、简单类型数组或字符串类型 RDD 之间 <code>shuffle</code> 时，在内部使用 <code>Kryo serializer</code>。</p><p>Spark 默认包含 <code>Kryo</code> 序列化器，用于 <a href="https://github.com/twitter/chill" target="_blank" rel="noopener noreferrer">Twitter chill</a> 库中 <code>AllScalaRegistrar</code> 涉及的许多常用的Scala核心类。</p><p>要向Kryo注册你自己的自定义类，请使用 <code>registerKryoClasses</code> 方法。</p><div class="language-scala codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#F8F8F2;--prism-background-color:#282A36"><div class="codeBlockContent_biex"><pre tabindex="0" class="prism-code language-scala codeBlock_bY9V thin-scrollbar"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#F8F8F2"><span class="token plain">val conf = new SparkConf().setMaster(...).setAppName(...)</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">conf.registerKryoClasses(Array(classOf[MyClass1], classOf[MyClass2]))</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">val sc = new SparkContext(conf)</span><br></span></code></pre><div class="buttonGroup__atx"><button type="button" aria-label="Copy code to clipboard" title="Copy" class="clean-btn"><span class="copyButtonIcons_eSgA" aria-hidden="true"><svg class="copyButtonIcon_y97N" viewBox="0 0 24 24"><path d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg class="copyButtonSuccessIcon_LjdS" viewBox="0 0 24 24"><path d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div><p><a href="https://github.com/EsotericSoftware/kryo" target="_blank" rel="noopener noreferrer">Kryo文档</a> 描述了更高级的注册选项，如添加自定义序列化代码。</p><p>如果你的对象很大，你可能还需要增加 <code>spark.kryoserializer.buffer</code> 。这个值需要足够大，以容纳你要序列化的<em>最大</em>对象。</p><p>最后，如果你不注册自定义类，Kryo仍然可以工作，但是它必须将完整的类名存储在每个对象中，这是很浪费资源的。</p><h2 class="anchor anchorWithStickyNavbar_LWe7" id="内存调优">内存调优<a class="hash-link" href="#内存调优" title="Direct link to heading">​</a></h2><p>在内存使用时进行调优，有三个考虑因素:</p><ul><li><code>内存大小</code>： 对象使用的内存 <em>大小</em> (你可能希望整个 <code>dataset</code> 都能在内存中)</li><li><code>成本</code>： 访问对象的<em>成本</em></li><li><code>开销</code>： <code>gc</code> 开销(如果对象的周转率很高)。</li></ul><p>默认情况下，Java对象的访问速度很快，但是很容易比字段中的 “原始(raw)” 数据多消耗2-5倍的内存空间。这是由于以下几个原因造成的:</p><ul><li>每个不同的 Java 对象都有一个&quot;对象头&quot;，它大约有16个字节，包含指向其类的指针等信息。对于一个只有很少数据的对象(比如一个 <code>Int</code> 字段)，它可比数据大。</li></ul><ul><li>Java  <code>String</code> 在原始字符串数据上大约有40个字节的开销(因为他们将其存储在 <code>Char</code> 数组中，并保留额外的数据，如长度)，由于 <code>String</code> 内部使用 UTF-16 编码，因此将每个字符存储为 <em><code>2字节</code></em>。因此，一个10个字符的字符串可以轻松地消耗60字节空间。</li><li>常见的集合类，如 <code>HashMap</code> 和 <code>LinkedList</code>，使用链接数据结构，其中每个元素都有一个 &quot;wrapper&quot; 对象(例如“Map.Entry”)。这个对象不仅有一个头，而且还有指向列表中下一个对象的地址指针(通常每个地址指针有 <code>8</code> 个字节)。</li><li>原始类型的集合通常将它们存储为 <code>boxed </code>(装箱) 对象，如 <code>java.lang.Integer</code></li></ul><p>本节将首先概述Spark中的内存管理，然后讨论用户可以采取的具体策略，以便在他/她的应用程序中更有效地使用内存。特别地，我们将描述如何确定对象的内存使用情况，以及如何改进它——通过更改数据结构或以序列化格式存储数据。然后，我们将讨论调整Spark的 <code>cache size</code> 和<code> Java gc</code>。</p><h3 class="anchor anchorWithStickyNavbar_LWe7" id="内存管理概论">内存管理概论<a class="hash-link" href="#内存管理概论" title="Direct link to heading">​</a></h3><p>Spark中的内存使用主要分为两类: 执行和存储。</p><ul><li>执行内存: 是指用于 <code>shuffle</code> 、<code>join</code>、<code>sort</code> 和 <code>aggregation</code> 的计算</li><li>存储内存: 是指用于在集群中 <code>cache</code> 和传播内部数据的内存。</li></ul><p>在Spark中，执行和存储共享一个统一的区域(<code>M</code>)，当没有执行内存时，存储可以获取所有可用的内存，反之亦然。如果有必要，执行可能会驱逐存储，但仅在总存储内存使用量低于某个阈值(<code>R</code>)时才会这样做。换句话说，<code>R</code> 描述了 <code>M</code> 中的一个子区域，其中缓存的块永远不会被驱逐。存储可能不会因为执行的复杂性而驱逐执行。</p><p>这种设计确保了几个理想的性能。首先，不使用缓存的应用程序可以将整个空间用于执行，从而避免不必要的磁盘溢出。其次，使用缓存的应用程序可以保留最小的存储空间(R)，在这里它们的数据块不会被清除。最后，这种方法为各种工作负载提供了合理的开箱即用性能，而不需要用户了解如何在内部划分内存。</p><p>虽然有两种相关的配置，但是典型的用户不应该需要调整它们，因为默认值适用于大多数工作负载:</p><ul><li><code>spark.memory.fraction</code> 表示 <code>M</code> 的大小是(JVM <code>heap space</code>- 300MB)的一部分(默认值0.6)。剩下的空间(40%)用于用户数据结构、Spark中的内部元数据，以及在稀疏和异常大的记录情况下防止 <code>OOM</code> 错误。</li><li><code>spark.memory.storageFraction</code> 将 <code>R</code> 的大小表示为 <code>M</code> 的一部分(默认值为0.5)。<code>R</code> 是 <code>M</code> 中的存储空间，缓存的块不会被执行清除。</li></ul><ul><li>应该设置 <code>spark.memory.fraction</code> 的值，以便在JVM的 <code>老年代(old)</code>或 <code>永久代(tenured)</code>中合适地容纳这部分堆空间。有关详细信息，请参阅下面关于 高级 GC调优的讨论。</li></ul><h3 class="anchor anchorWithStickyNavbar_LWe7" id="确定内存消耗">确定内存消耗<a class="hash-link" href="#确定内存消耗" title="Direct link to heading">​</a></h3><p>确定一个 <code>dataset</code> 所需的内存消耗的最好方法是创建一个RDD，将它放到缓存中，然后在web UI中查看 “Storage” 页面。该页将告诉你RDD占用了多少内存。</p><p>要估算特定对象的内存消耗，请使用 <code>SizeEstimator</code> 的 <code>estimate</code> 方法。这对于尝试使用不同的数据布局来调整内存使用，以及确定广播变量在每个执行器堆上占用的空间量非常有用。</p><h3 class="anchor anchorWithStickyNavbar_LWe7" id="优化数据结构">优化数据结构<a class="hash-link" href="#优化数据结构" title="Direct link to heading">​</a></h3><p>减少内存消耗的第一种方法是避免使用增加开销的Java特性，比如 <code>pointer-based</code> 的数据结构和 <code>wrapper</code> 对象。</p><p>有几种方法可以做到这一点:</p><ol><li>设计你自己的数据结构以选择对象数组和基本类型，而不是标准的 <code>Java</code> 或 <code>Scala</code> 集合类(e.g. <code>HashMap</code>)。<a href="http://fastutil.di.unimi.it/" target="_blank" rel="noopener noreferrer">fastutil</a>  库为与 <code>Java</code>标准 library 兼容的基本类型提供了方便的集合类。</li><li>尽可能避免嵌套有大量小对象和指针的结构。</li><li>考虑使用数字id或枚举对象代替 <code>key</code> 的字符串。</li><li>如果你的内存不足32 GB，那么可以设置 JVM参数 <code>-XX:+UseCompressedOops</code>，使地址指针变成4个字节，而不是8个字节。你可以在 <code>spark-env.sh</code> 中添加这些选项。</li></ol><h3 class="anchor anchorWithStickyNavbar_LWe7" id="rdd_serialized">序列化 RDD 存储<a class="hash-link" href="#rdd_serialized" title="Direct link to heading">​</a></h3><p>当对象仍过于庞大,尽管进行了上述调优，仍无法有效地进行存储。 减少内存使用一个更简单的方法是将它们用 <em><code>serialized</code></em> 形式进行存储。 在 <a href="http://spark.apache.org/docs/latest/rdd-programming-guide.html#rdd%E6%8C%81%E4%B9%85%E5%8C%96" target="_blank" rel="noopener noreferrer">RDD 持久 API</a> 使用序列化 StorageLevels, 如 <code>MEMORY_ONLY_SER</code>。Spark 然后将每个RDD分区存储为一个大字节数组。以序列化形式存储数据的惟一缺点是访问时间较慢，因为必须动态地反序列化每个对象。如果你希望以序列化的形式缓存数据，我们强烈建议<a href="#%E6%95%B0%E6%8D%AE%E5%BA%8F%E5%88%97%E5%8C%96">使用Kryo</a>，因为它比Java序列化(当然也比原始Java对象)的大小小得多。</p><h3 class="anchor anchorWithStickyNavbar_LWe7" id="gc优化">GC优化<a class="hash-link" href="#gc优化" title="Direct link to heading">​</a></h3><p>当你的程序存储了大量的 <code>RDD</code> 数据时， <code>JVM GC</code> 可能会成为一个问题。(对于那些只读取一次RDD，然后在上面运行许多操作的程序来说，这通常不是问题。)当Java需要清除旧对象来为新对象腾出空间时，它将需要跟踪所有Java对象并找到未使用的对象。这里要记住的要点是，GC成本与Java对象的数量<em>成比例，因此使用对象较少的数据结构(例如，一个 <code>Int</code> 数组而不是 <code>LinkedList</code>数组)可以大大降低这一成本。一个更好的方法是以序列化的形式持久化对象，如上所述:现在每个RDD分区将只有 </em>一个* 对象(一个字节数组)。在尝试其他技术之前，如果GC有问题，首先要尝试的是使用 <a href="#rdd_serialized">序列化缓存</a> 。</p><p>GC也可能是一个问题，因为任务的工作内存(运行任务所需的空间量)和节点上缓存的 <code>RDD</code> 之间存在干扰。我们将讨论如何控制分配给RDD缓存的空间来缓解这种情况。</p><p><strong>测量GC的影响</strong></p><p>GC调优的第一步是收集关于 GC发生的频率和GC花费的时间的统计信息。这可以通过在Java 参数中添加 <code>-verbose:gc -XX:+PrintGCDetails -XX:+PrintGCTimeStamps</code> 来实现。下一次运行Spark作业时，你将看到每次发生垃圾收集时在 <code>Worker</code> 日志中打印的消息。注意，这些日志将在你的集群<code>Worker 节点</code> 上(在它们的工作目录中的 <code>stdout</code> 文件中)，而不是在你的 Driver 进程上。</p><p><strong>高级GC调优</strong></p><p>为了进一步调优 GC，我们首先需要了解JVM中关于内存管理的一些基本信息:</p><ul><li>Java堆空间分为两个区域，年轻代(<code>Young</code>) 和老年代(<code>Old</code>) 。年轻代的目的是持有生命周期较短（short-object）的对象，而老年代的目的是持有具有更长的生存期的对象。</li><li>年轻一代被进一步划分为三个区域<!-- -->[<code>Eden</code>, <code>Survivor1</code>, <code>Survivor2</code>]<!-- -->。</li><li>GC 过程的简化描述:<ul><li>当Eden已满时，在Eden上运行一个小型GC，从Eden和Survivor1存活的对象被复制到Survivor2。交换<code>Survivor</code> 区域。</li><li>如果一个对象足够 Old(在多次GC后还存活) 或Survivor2已满，则将其移动到老年代中。</li><li>最后，当老年代接近full时，将调用full GC。</li></ul></li></ul><p>在Spark中进行GC调优的目标是确保在老年代中只存储长期存在的 <code>RDD</code>，而年轻代的大小足以存储短期存在的对象。这将有助于避免在任务执行期间发生 <code>full gc</code> 来收集创建的临时对象。一些可能有用的步骤是:</p><ul><li>通过收集GC统计信息来检查是否有太多的 <code>GC</code> 发生。如果在任务完成之前多次调用 <code>full GC</code>，这意味着没有足够的可用内存来执行任务。</li><li>如果 <code>Minor GC</code> 太多而 <code>Major GC</code> 太少，那么为Eden分配更多的内存会有所帮助。你可以将Eden的大小设置为高估 (over-estimate) 每个 <code>task</code> 所需的内存大小。如果 <code>Eden</code> 的大小被确定为 <code>E</code>，那么你可以使用选项 <code>-Xmn=4/3*E</code> 来设置年轻代的大小。（4/3的比例也考虑到了 <code>Survivor</code> 区域使用的空间, 一个 <code>Survivor</code> 占年轻代 1/8 空间）</li><li>在打印的GC统计中，如果老年代空间接近满，通过降低 <code>spark.memory.fraction</code> 来减少用于缓存的内存数量; 缓存更少的对象比降低任务执行速度要好。或者，考虑减少年轻代的规模。这意味着降低 <code>-Xmn</code>，如果你已经设置为上述。如果没有，请尝试更改JVM的 <code>NewRatio</code> 参数的值。许多 JVM 将其默认为2，这意味着老一代占用了2/3的堆。它应该足够大，使这个 <code>fraction</code> 超过 <code>spark.memory.fraction</code>。</li><li>尝试使用JVM参数 <code>-XX:+UseG1GC</code> 使用的 <code>G1GC</code> 垃圾收集器。在垃圾收集成为瓶颈的某些情况下，它可以提高性能。注意， 对于 <code>Executor</code> 堆大小容量大的集群, 用 <code>-XX:G1HeapRegionSize</code> 参数增加 <a href="http://www.oracle.com/technetwork/articles/java/g1gc-1984535.html" target="_blank" rel="noopener noreferrer">G1 区域尺寸</a>  会很重要。</li><li>例如，如果你的任务正在从HDFS读取数据，则可以使用从HDFS读取的数据块的大小来估计任务所使用的内存量。 注意，解压缩块的大小通常是块大小的2到3倍。因此，如果我们希望有3或4个任务的工作空间，并且 <code>HDFS</code> 块大小为128MB，我们可以估计Eden的大小为 <code>4*3*128MB</code>。</li><li>监视随新设置的变化, GC 所花费的频率和时间。</li></ul><p>我们的经验表明，GC调优的效果取决于你的应用程序和可用的内存量。官网描述了<a href="https://docs.oracle.com/javase/8/docs/technotes/guides/vm/gctuning/index.html" target="_blank" rel="noopener noreferrer">更多的调优选项</a>，但是在高层次上，管理 <code>full GC</code> 发生的频率有助于减少开销。</p><p>可以通过在 Job 配置中，设置 <code>spark.executor.extraJavaOptions</code> 来指定 <code>Executor</code> 的GC调优等级。</p><h2 class="anchor anchorWithStickyNavbar_LWe7" id="其它考虑">其它考虑<a class="hash-link" href="#其它考虑" title="Direct link to heading">​</a></h2><h3 class="anchor anchorWithStickyNavbar_LWe7" id="并行级别">并行级别<a class="hash-link" href="#并行级别" title="Direct link to heading">​</a></h3><p>除非将每个 <code>operation</code> 的并行度设置得足够高，否则集群资源不会得到充分利用。Spark根据每个文件的大小自动设置要在每个文件上运行的“map” 任务的数量(尽管你可以通过 <code>SparkContext.textFile</code> 的可选参数来控制它)。对于分布式的“reduce”操作，例如 <code>groupByKey</code> 和 <code>reduceByKey</code>，它使用最大的父RDD的分区数。你可以将并行度级别作为第二个参数传递(参见 <a href="http://spark.apache.org/docs/latest/api/scala/index.html#org.apache.spark.rdd.PairRDDFunctions" target="_blank" rel="noopener noreferrer">spark.PairRDDFunction</a> 文件)，或者设置配置属性<code>spark.default.parallelism</code> 来更改默认值。通常，我们建议在你的集群中每个CPU内核执行2-3个任务。</p><h3 class="anchor anchorWithStickyNavbar_LWe7" id="reduce任务内存使用">Reduce任务内存使用<a class="hash-link" href="#reduce任务内存使用" title="Direct link to heading">​</a></h3><p>有时，你会得到一个OutOfMemoryError错误，不是因为你的RDD 内存不合适，而是因为你的一个任务的工作集，例如 <code>groupByKey</code> 中的一个 <code>reduce</code> 任务，占用内存太多。Spark的 <code>shuffle</code> 操作( <code>sortByKey</code>、<code>groupByKey</code>、<code>reduceByKey</code>、<code>join</code>等)在每个任务中构建一个 <code>hash table</code> 来执行分组，分组常常很大。这里最简单的修复方法是增加并行度，这样每个任务的输入集就会更小。Spark可以有效地支持短至200 ms的任务，因为它跨多个任务重用一个 <code>executor JVM</code>，而且它的任务启动成本很低，所以可以安全地将并行度提高到比集群中的内核数量更多的水平。</p><h3 class="anchor anchorWithStickyNavbar_LWe7" id="广播大变量">广播大变量<a class="hash-link" href="#广播大变量" title="Direct link to heading">​</a></h3><p>使用SparkContext中可用的<a href="http://spark.apache.org/docs/latest/rdd-programming-guide.html#%E5%B9%BF%E6%92%AD%E5%8F%98%E9%87%8F" target="_blank" rel="noopener noreferrer">广播功能</a>可以极大地减少每个序列化任务的大小，以及通过集群启动 job 的成本。如果你的任务使用了 <code>Driver</code> 进程中的任何大对象(例如，一个 static 查找表)，请考虑将其转换为广播变量。Spark在 <code>Master</code> 上记录了每个任务的序列化大小，因此可以查看它来决定你的任务是否太大;一般情况下，大于20kb的任务可能值得优化。</p><h3 class="anchor anchorWithStickyNavbar_LWe7" id="数据局部性">数据局部性<a class="hash-link" href="#数据局部性" title="Direct link to heading">​</a></h3><p>数据局部性对Spark作业的性能有很大的影响。如果数据和对其进行操作的代码在一起，那么计算往往会很快。但是，如果代码和数据是分开的，那么其中一个必须转移到另一个。通常，将序列化的代码从一个地方传送到另一个地方要比传送数据块快得多，因为代码的大小比数据小得多。Spark根据数据局部性的一般原则构建其调度。</p><p>数据局部性是指数据与处理数据的代码之间的距离。基于数据的当前位置有几个级别的局部性。按从最近到最远的顺序排列:</p><ul><li><p><code>PROCESS_LOCAL</code> : 数据与运行代码位于相同的<code>JVM</code>中。这是最好的位置特性。</p></li><li><p><code>NODE_LOCAL</code>:  数据在同一个节点上。数据可能在同一节点上的 <code>HDFS</code> 中，也可能在同一节点上的另一个 <code>Executor</code> 中。这比 <code>PROCESS_LOCAL</code> 稍微慢一些，因为数据必须在进程之间传递</p></li><li><p><code>NO_PREF</code> : 数据从任何地方访问, 速度都一样快，并且没有区域性优先特性</p></li><li><p><code>RACK_LOCAL</code>:  数据位于相同的服务器机架上。数据位于同一机架上的不同服务器上，因此需要通过网络发送，通常是通过单个交换机</p></li><li><p><code>Any</code>:  数据都在网络的其他地方，不在同一个机架上</p></li></ul><p>Spark倾向于将所有任务安排在最佳位置级别，但这并不总是可能的。在任何空闲执行器上都没有未处理的数据的情况下，Spark切换到较低的位置级别。有两种选择:</p><p>a)等待繁忙的CPU释放出来，在同一服务器上的数据上启动一个任务，或者</p><p>b)立即在需要移动数据的较远的地方启动一个新任务。</p><p>Spark通常做的是稍作等待，希望繁忙的CPU可以释放。一旦超时过期，它就开始将数据从远处移动到空闲的CPU。每个级别之间回退的等待超时可以单独配置，也可以全部配置在一个参数中; 有关详细信息，见 配置页面 <code>spark.locality</code>参数 。如果你的任务很长，并且位置不好，你应该增加这些设置，但是默认设置通常工作得很好。</p><h2 class="anchor anchorWithStickyNavbar_LWe7" id="总结">总结<a class="hash-link" href="#总结" title="Direct link to heading">​</a></h2><p>这是一个简短的指南，指出了你在调优Spark应用程序时应该了解的主要问题——最重要的是数据序列化和内存调优。对于大多数程序，切换到Kryo序列化并以序列化的形式持久化数据将解决最常见的性能问题。你可以在<a href="https://spark.apache.org/community.html" target="_blank" rel="noopener noreferrer">Spark邮件列表中</a> 询问其他调优最佳实践。</p></div></article><nav class="pagination-nav docusaurus-mt-lg" aria-label="Docs pages navigation"><a class="pagination-nav__link pagination-nav__link--prev" href="/wiki/docs/bigdata/hadoop/hadoop-tuning"><div class="pagination-nav__sublabel">Previous</div><div class="pagination-nav__label">hadoop 性能优化</div></a><a class="pagination-nav__link pagination-nav__link--next" href="/wiki/docs/bigdata/spark/strategies-of-spark-join"><div class="pagination-nav__sublabel">Next</div><div class="pagination-nav__label">Spark Join Strategies</div></a></nav></div></div><div class="col col--3"><div class="tableOfContents_bqdL thin-scrollbar theme-doc-toc-desktop"><ul class="table-of-contents table-of-contents__left-border"><li><a href="#数据序列化" class="table-of-contents__link toc-highlight">数据序列化</a></li><li><a href="#内存调优" class="table-of-contents__link toc-highlight">内存调优</a><ul><li><a href="#内存管理概论" class="table-of-contents__link toc-highlight">内存管理概论</a></li><li><a href="#确定内存消耗" class="table-of-contents__link toc-highlight">确定内存消耗</a></li><li><a href="#优化数据结构" class="table-of-contents__link toc-highlight">优化数据结构</a></li><li><a href="#rdd_serialized" class="table-of-contents__link toc-highlight">序列化 RDD 存储</a></li><li><a href="#gc优化" class="table-of-contents__link toc-highlight">GC优化</a></li></ul></li><li><a href="#其它考虑" class="table-of-contents__link toc-highlight">其它考虑</a><ul><li><a href="#并行级别" class="table-of-contents__link toc-highlight">并行级别</a></li><li><a href="#reduce任务内存使用" class="table-of-contents__link toc-highlight">Reduce任务内存使用</a></li><li><a href="#广播大变量" class="table-of-contents__link toc-highlight">广播大变量</a></li><li><a href="#数据局部性" class="table-of-contents__link toc-highlight">数据局部性</a></li></ul></li><li><a href="#总结" class="table-of-contents__link toc-highlight">总结</a></li></ul></div></div></div></div></main></div></div></div>
<script src="/wiki/assets/js/runtime~main.356aa08e.js"></script>
<script src="/wiki/assets/js/main.5a4fb01b.js"></script>
</body>
</html>